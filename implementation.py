# -*- coding: utf-8 -*-
"""Implementation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YZJPsO_iZr6Mfo5_Lcf9PIGjeJc88V2m
"""

!pip install brainweb

"""# Open dataset

"""

from __future__ import print_function, division
import brainweb
from brainweb import volshow
import numpy as np
from os import path
from tqdm.auto import tqdm
import logging
import matplotlib.pyplot as plt
import cv2
logging.basicConfig(level=logging.INFO)

files = brainweb.get_files()

data = brainweb.load_file(files[1])
# data = brainweb.load_file('t1_icbm_normal_1mm_pn3_rf20.rawb.gz')

print(files[-1])
volshow(data, cmaps=['gist_ncar']);

print(files[-1])
volshow(data, cmaps=['gray']);

np.random.shuffle(files)

!rm -r Dataset

!mkdir Dataset
!mkdir Dataset/Train
!mkdir Dataset/Test

dataset_train = []
i = 0
subset = 'Train'
for f in files[:17]:
    data = brainweb.load_file(f)
    data = (data - data.min()) / (data.max() - data.min())
    data = (data * 255).astype(np.uint8)
    dataset_train.append(data[170, :, :])
    dataset_train.append(data[175, :, :])
    dataset_train.append(data[180, :, :])
    dataset_train.append(data[185, :, :])
    dataset_train.append(data[190, :, :])

    cv2.imwrite(f'Dataset/{subset}/{i}.png', cv2.resize(data[170, :, :], (181, 217)))
    cv2.imwrite(f'Dataset/{subset}/{i + 1}.png', cv2.resize(data[175, :, :], (181, 217)))
    cv2.imwrite(f'Dataset/{subset}/{i + 2}.png', cv2.resize(data[180, :, :], (181, 217)))
    cv2.imwrite(f'Dataset/{subset}/{i + 3}.png', cv2.resize(data[185, :, :], (181, 217)))
    cv2.imwrite(f'Dataset/{subset}/{i + 4}.png', cv2.resize(data[190, :, :], (181, 217)))
    i += 5

dataset_test = []
i = 0
subset = 'Test'
for f in files[17:]:
    data = brainweb.load_file(f)
    data = (data - data.min()) / (data.max() - data.min())
    data = (data * 255).astype(np.uint8)
    dataset_test.append(data[170, :, :])
    dataset_test.append(data[175, :, :])
    dataset_test.append(data[180, :, :])
    dataset_test.append(data[185, :, :])
    dataset_test.append(data[190, :, :])

    cv2.imwrite(f'Dataset/{subset}/{i}.png', cv2.resize(data[170, :, :], (181, 217)))
    cv2.imwrite(f'Dataset/{subset}/{i+1}.png', cv2.resize(data[175, :, :], (181, 217)))
    cv2.imwrite(f'Dataset/{subset}/{i + 2}.png', cv2.resize(data[180, :, :], (181, 217)))
    cv2.imwrite(f'Dataset/{subset}/{i + 3}.png', cv2.resize(data[185, :, :], (181, 217)))
    cv2.imwrite(f'Dataset/{subset}/{i + 4}.png', cv2.resize(data[190, :, :], (181, 217)))
    i += 5

dataset_train = np.array(dataset_train)
dataset_test = np.array(dataset_test)

dataset_train.shape

plt.hist(dataset_test.reshape(-1), bins=50)

"""# Dataset"""

from torch.utils.data import Dataset, DataLoader
from scipy.stats import rice
from scipy.ndimage import rotate
from glob import glob

plt.imshow(rice.rvs(1, size=(125, 125), scale=61 ** 0.5))
plt.colorbar()

class MRIDataset(Dataset):
    def __init__(self, image_path, noise_range, patch_size, is_test, specific_noise_level=None):
        super().__init__()
        self.noise_range = noise_range
        self.patch_size = patch_size
        self.is_test = is_test
        self.specific_noise_level = specific_noise_level
        self.images = self.load_images(image_path)
        self.images = self.get_patches()

    def get_patches(self):
        xs = np.arange(0, self.images.shape[3] - self.patch_size, self.patch_size // 2)
        ys = np.arange(0, self.images.shape[2] - self.patch_size, self.patch_size // 2)
        xs, ys = np.meshgrid(xs, ys)
        patched_images = []
        for patch_x, patch_y in zip(xs.reshape(-1), ys.reshape(-1)):
            patch_image = self.images[:, :, patch_y:patch_y + self.patch_size, patch_x:patch_x + self.patch_size]
            patched_images.append(patch_image)

        patched_images = np.vstack(patched_images)
        return patched_images

    def load_images(self, image_path):
        images = [cv2.imread(image, 0) for image in glob(image_path)]
                                         # Channel first
        return np.array(images).reshape(-1, 1, images[0].shape[0], images[0].shape[1])

    def clip(self, image):
        return np.clip(image, np.random.randint(0, 40), np.random.randint(215, 255))

    def rotate(self, image):
        angle = np.random.randint(-10, 10)
        return rotate(image, angle, reshape=False, mode='nearest')

    def noise(self, image):
        if self.specific_noise_level is not None:
            noise_value = self.specific_noise_level
        elif len(self.noise_range) == 2:
            noise_value = np.random.random()
            noise_value = noise_value * (self.noise_range[1] - self.noise_range[0])
            noise_value = noise_value + self.noise_range[0]
        else:
            noise_value = np.random.choice(self.noise_range)

        noise_value = noise_value * image.max()
        noise_value = rice.rvs(b=np.sqrt(2) * noise_value, size=image.shape[1:3], scale=noise_value)
        noise_value = noise_value - noise_value.mean()
        return np.clip(noise_value + image, 0, 255)

    def __len__(self):
        return self.images.shape[0]

    def __getitem__(self, idx):
        image = self.images[idx]
        if not self.is_test:
            image = self.clip(image)
            image = self.rotate(image)

        image_noise = self.noise(image)
        return (image_noise - 255) / 255, (image - 255) / 255

train_dataset = MRIDataset('Dataset/Train/*.png', [0, 0.24], 21, False)
test_dataset = MRIDataset('Dataset/Test/*.png', [0, 0.24], 21, True)

train_dataset.images.shape

image = cv2.imread('Dataset/Test/0.png', 0)
image_noise = train_dataset.noise(image.reshape(1, image.shape[0], image.shape[1]))[0]
plt.subplot(1, 2, 1)
plt.imshow(image, cmap='gray')
plt.subplot(1, 2, 2)
plt.imshow(image_noise, cmap='gray')

image_noise, image = train_dataset[500]
plt.subplot(1, 2, 1)
plt.imshow(image[0], cmap='gray')
plt.subplot(1, 2, 2)
plt.imshow(image_noise[0], cmap='gray')

"""# Build model"""

import torch
from torch import nn

class WDNNBlock(nn.Module):
    def __init__(self, in_channels, out_channels, bn=False):
        super().__init__()

        if bn:
            self.conv = nn.Sequential(
                nn.Conv2d(in_channels=in_channels,
                        out_channels=out_channels,
                        kernel_size=3,
                        stride=1,
                        padding=1),
                nn.BatchNorm2d(num_features=out_channels),
                nn.ReLU()
            )
        else:
            self.conv = nn.Sequential(
                nn.Conv2d(in_channels=in_channels,
                        out_channels=out_channels,
                        kernel_size=3,
                        stride=1,
                        padding=1),
                nn.ReLU()
            )

        nn.init.kaiming_normal_(self.conv[0].weight, mode='fan_in', nonlinearity='relu')
        nn.init.zeros_(self.conv[0].bias)

    def forward(self, x):
        return self.conv(x)


class WDNN(nn.Module):
    def __init__(self):
        super().__init__()

        self.conv = nn.Sequential(
            WDNNBlock(in_channels=1, out_channels=192, bn=False),  # 1
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 2
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 3
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 4
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 5
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 6
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 7
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 8
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 9
            WDNNBlock(in_channels=192, out_channels=1, bn=False), # 10
        )

    def forward(self, x):
        return self.conv(x)

"""# Training and Inference utils"""

from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm_notebook as tqdm
import matplotlib.pyplot as plt

!mkdir logs
!mkdir models

# Letting z be the observed image
# x the latent clean image, the network is situated to predict the noise v;
# in other words, the residual learning formulation is used to train a residual mapping F(z) ≈ v,
# and then we have x=z−F(z).

def taining_epoch(model, train_dataloader, optimizer, criterion, writer, init_step, device):
    i = init_step
    total_loss = 0
    n_samples = 0
    for data in tqdm(train_dataloader):
        z = data[0].float().to(device)
        x = data[1].float().to(device)

        v = model(z)

        loss = criterion(v, (z - x))
        writer.add_scalar('Train/loss', loss.item(), i)
        total_loss += loss.item() * z.shape[0]
        n_samples += z.shape[0]

        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        i += 1

    avg_loss = total_loss / n_samples
    print(f'Average Training Loss for Epoch: {avg_loss}')
    return model, i, avg_loss

def validation_epoch(model, test_dataloader, criterion, writer, init_step, device):
    total_loss = 0
    n_samples = 0
    for data in tqdm(test_dataloader):
        z = data[0].float().to(device)
        x = data[1].float().to(device)

        with torch.no_grad():
            v = model(z)
            loss = criterion(v, (z - x))
            total_loss += loss.item() * z.shape[0]
            n_samples += z.shape[0]

    avg_loss = total_loss / n_samples
    print(f'Average Validation Loss for Epoch: {avg_loss}')
    writer.add_scalar('Validation/loss', avg_loss, init_step)
    return model, avg_loss

def train(model, epoch, train_dataloader, test_dataloader, optimizer, criterion, lr, train_name, device):
    writer = SummaryWriter('logs/' + train_name)
    init_step = 0
    train_losses = []
    val_losses = []
    for e in range(epoch):
        print(f'---------------- Epoch {e+1} ----------------')
        model.train()
        model, init_step, train_loss = taining_epoch(model, train_dataloader, optimizer, criterion, writer, init_step, device)
        train_losses.append(train_loss)
        model.eval()
        model, val_loss = validation_epoch(model, test_dataloader, criterion, writer, e, device)
        val_losses.append(val_loss)
        lr_scheduler.step()

    # Plotting the losses
    plt.figure(figsize=(10,5))
    plt.title("Training and Validation Loss")
    plt.plot(train_losses,label="Train")
    plt.plot(val_losses,label="Validation")
    plt.xlabel("epochs")
    plt.ylabel("Loss")
    plt.legend()
    plt.show()

    return model

def get_noisy_image(image, noise_value):
    noise_value = noise_value * image.max()
    noise_value = rice.rvs(b=np.sqrt(2) * noise_value, size=image.shape[:2], scale=noise_value)
    noise_value = noise_value - noise_value.mean()
    return np.clip(noise_value + image, 0, 255)


def inference(model, image_noise, device):
    image_noise_input = torch.from_numpy(image_noise)[None, None].float().to(device)
    image_noise_input = (image_noise_input - 255) / 255
    with torch.no_grad():
        pred = model(image_noise_input)
        image_denoise = (image_noise_input - pred).cpu().numpy()

    return (image_denoise[0, 0] * 255) + 255

from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
from skimage.metrics import normalized_mutual_information as nmi
import pandas as pd

"""# Part 0: training WDNN21"""

WDNN21 = WDNN()

WDNN21.load_state_dict(torch.load('models/WDNN21.pth'))

train_dataset = MRIDataset('Dataset/Train/*.png', [0, 0.24], 21, False, specific_noise_level=0.21)
test_dataset = MRIDataset('Dataset/Train/*.png', [0, 0.24], 21, True, specific_noise_level=0.21)

train_dataloader = DataLoader(train_dataset, 128, shuffle=True, num_workers=16)
test_dataloader = DataLoader(test_dataset, 128, shuffle=True, num_workers=16)

optimizer = torch.optim.Adam(WDNN21.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08)

criterion = nn.L1Loss()

epochs = 50

lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.01**(1/100))
# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, (1e-4 / 1e-2) ** (1 / 50))
# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 1)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
WDNN21 = WDNN21.to(device)

train(WDNN21, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNN21', device)

WDNN21 = WDNN21.eval()

for image in glob('Dataset/Test/*.png'):
    image = cv2.imread(image, 0)

    image_noise = get_noisy_image(image, 0.21)
    image_denoise = inference(WDNN21, image_noise, device)

    plt.subplot(1, 4, 1)
    plt.title("Original")
    plt.imshow(image, cmap='gray')
    plt.subplot(1, 4, 2)
    plt.title("Noisy Image")
    plt.imshow(image_noise, cmap='gray')
    plt.subplot(1, 4, 3)
    plt.title("Denoised Image")
    plt.imshow(image_denoise, cmap='gray')
    plt.subplot(1, 4, 4)
    plt.title("Noise")
    plt.imshow(image_denoise-image_noise, cmap='gray')
    plt.show()
    image_noise = get_noisy_image(image, 0.21)

noise_levels = [0.21]
metrics_WDNN21 = pd.DataFrame({'PSNR': [0], 'SSIM': [0], 'NMI': [0]}, index=noise_levels)
metrics_noisy = pd.DataFrame({'PSNR': [0], 'SSIM': [0], 'NMI': [0]}, index=noise_levels)

n_images = 0
for image in tqdm(glob('Dataset/Test/*.png')):
    image = cv2.imread(image, 0)
    n_images += 1
    for noise_level in noise_levels:
        image_noise = get_noisy_image(image, noise_level)
        image_denoise = inference(WDNN21, image_noise, device)

        metrics_WDNN21.loc[noise_level, 'PSNR'] += psnr(image, image_denoise)
        metrics_WDNN21.loc[noise_level, 'SSIM'] += ssim(image, image_denoise)
        metrics_WDNN21.loc[noise_level, 'NMI'] += nmi(image, image_denoise)

        metrics_noisy.loc[noise_level, 'PSNR'] += psnr(image, image_noise)
        metrics_noisy.loc[noise_level, 'SSIM'] += ssim(image, image_noise)
        metrics_noisy.loc[noise_level, 'NMI'] += nmi(image, image_noise)

metrics_WDNN21 = metrics_WDNN21 / n_images
metrics_noisy = metrics_noisy / n_images

metrics_WDNN21

metrics_noisy

torch.save(WDNN21.state_dict(), 'models/WDNN21.pth')

"""# Part 0: training WDNN17"""

WDNN17 = WDNN()

WDNN17.load_state_dict(torch.load('models/WDNN17.pth'))

train_dataset = MRIDataset('Dataset/Train/*.png', [0, 0.24], 21, False, specific_noise_level=0.17)
test_dataset = MRIDataset('Dataset/Train/*.png', [0, 0.24], 21, True, specific_noise_level=0.17)

train_dataloader = DataLoader(train_dataset, 128, shuffle=True, num_workers=16)
test_dataloader = DataLoader(test_dataset, 128, shuffle=True, num_workers=16)

optimizer = torch.optim.Adam(WDNN17.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08)

criterion = nn.L1Loss()

epochs = 50

lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.01**(1/100))
# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, (1e-4 / 1e-2) ** (1 / 50))
# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 1)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
WDNN17 = WDNN17.to(device)

train(WDNN17, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNN17', device)

WDNN17 = WDNN17.eval()

for image in glob('Dataset/Test/*.png'):
    image = cv2.imread(image, 0)
    image_noise = get_noisy_image(image, 0.17)
    image_denoise = inference(WDNN17, image_noise, device)
    plt.subplot(1, 4, 1)
    plt.title("Original")
    plt.imshow(image, cmap='gray')
    plt.subplot(1, 4, 2)
    plt.title("Noisy Image")
    plt.imshow(image_noise, cmap='gray')
    plt.subplot(1, 4, 3)
    plt.title("Denoised Image")
    plt.imshow(image_denoise, cmap='gray')
    plt.subplot(1, 4, 4)
    plt.title("Noise")
    plt.imshow(image_denoise-image_noise, cmap='gray')
    plt.show()

noise_levels = [0.17]
metrics_WDNN17 = pd.DataFrame({'PSNR': [0], 'SSIM': [0], 'NMI': [0]}, index=noise_levels)
metrics_noisy = pd.DataFrame({'PSNR': [0], 'SSIM': [0], 'NMI': [0]}, index=noise_levels)

n_images = 0
for image in tqdm(glob('Dataset/Test/*.png')):
    image = cv2.imread(image, 0)
    n_images += 1
    for noise_level in noise_levels:
        image_noise = get_noisy_image(image, noise_level)
        image_denoise = inference(WDNN17, image_noise, device)

        metrics_WDNN17.loc[noise_level, 'PSNR'] += psnr(image, image_denoise)
        metrics_WDNN17.loc[noise_level, 'SSIM'] += ssim(image, image_denoise)
        metrics_WDNN17.loc[noise_level, 'NMI'] += nmi(image, image_denoise)

        metrics_noisy.loc[noise_level, 'PSNR'] += psnr(image, image_noise)
        metrics_noisy.loc[noise_level, 'SSIM'] += ssim(image, image_noise)
        metrics_noisy.loc[noise_level, 'NMI'] += nmi(image, image_noise)

metrics_WDNN17 = metrics_WDNN17 / n_images
metrics_noisy = metrics_noisy / n_images

metrics_WDNN17

metrics_noisy

torch.save(WDNN17.state_dict(), 'models/WDNN17.pth')

"""# Part 1: training WDNN1"""

WDNN1 = WDNN()

WDNN1.load_state_dict(torch.load('models/WDNN1.pth'))

train_dataset = MRIDataset('Dataset/Train/*.png', [0, 0.24], 21, False)
test_dataset = MRIDataset('Dataset/Test/*.png', [0, 0.24], 21, True)

train_dataloader = DataLoader(train_dataset, 128, shuffle=True, num_workers=16)
test_dataloader = DataLoader(test_dataset, 128, shuffle=True, num_workers=16)

optimizer = torch.optim.Adam(WDNN1.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08)


criterion = nn.L1Loss()

epochs = 50

# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, (1e-4 / 1e-2) ** (1 / 50))
lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.01**(1/100))


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
WDNN1 = WDNN1.to(device)

train(WDNN1, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNN1', device)

WDNN1 = WDNN1.eval()

for image in glob('Dataset/Test/*.png'):
    image = cv2.imread(image, 0)
    image_noise = get_noisy_image(image, 0.21)
    image_denoise = inference(WDNN1, image_noise, device)
    plt.subplot(1, 4, 1)
    plt.title("Original")
    plt.imshow(image, cmap='gray')
    plt.subplot(1, 4, 2)
    plt.title("Noisy Image")
    plt.imshow(image_noise, cmap='gray')
    plt.subplot(1, 4, 3)
    plt.title("Denoised Image")
    plt.imshow(image_denoise, cmap='gray')
    plt.subplot(1, 4, 4)
    plt.title("Noise")
    plt.imshow(image_denoise-image_noise, cmap='gray')
    plt.show()

noise_levels = [0.035, 0.06, 0.09, 0.12, 0.15]

metrics_WDNN1 = pd.DataFrame({'PSNR': [0] * 5, 'SSIM': [0] * 5, 'NMI': [0] * 5}, index=noise_levels)
metrics_noisy = pd.DataFrame({'PSNR': [0] * 5, 'SSIM': [0] * 5, 'NMI': [0] * 5}, index=noise_levels)

n_images = 0
for image in tqdm(glob('Dataset/Test/*.png')):
    image = cv2.imread(image, 0)
    n_images += 1
    for noise_level in noise_levels:
        image_noise = get_noisy_image(image, noise_level)
        image_denoise = inference(WDNN1, image_noise, device)

        metrics_WDNN1.loc[noise_level, 'PSNR'] += psnr(image, image_denoise)
        metrics_WDNN1.loc[noise_level, 'SSIM'] += ssim(image, image_denoise)
        metrics_WDNN1.loc[noise_level, 'NMI'] += nmi(image, image_denoise)

        metrics_noisy.loc[noise_level, 'PSNR'] += psnr(image, image_noise)
        metrics_noisy.loc[noise_level, 'SSIM'] += ssim(image, image_noise)
        metrics_noisy.loc[noise_level, 'NMI'] += nmi(image, image_noise)

metrics_WDNN1 = metrics_WDNN1 / n_images
metrics_noisy = metrics_noisy / n_images

new_levels = [0.05, 0.09, 0.13, 0.17, 0.21]
metrics_WDNN1.index = new_levels
metrics_noisy.index = new_levels

metrics_WDNN1

metrics_noisy

plt.figure(figsize=(16, 4))
plt.subplot(1, 3, 1)
plt.plot(metrics_WDNN1.index, metrics_WDNN1['PSNR'], 'bo-', label='WDNN1')
plt.plot(metrics_noisy.index, metrics_noisy['PSNR'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNN1.index)
plt.ylabel('PSNR')
plt.grid()
plt.legend()

plt.subplot(1, 3, 2)
plt.plot(metrics_WDNN1.index, metrics_WDNN1['SSIM'], 'bo-', label='WDNN1')
plt.plot(metrics_noisy.index, metrics_noisy['SSIM'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNN1.index)
plt.ylabel('SSIM')
plt.grid()
plt.legend()

plt.subplot(1, 3, 3)
plt.plot(metrics_WDNN1.index, metrics_WDNN1['NMI'], 'bo-', label='WDNN1')
plt.plot(metrics_noisy.index, metrics_noisy['NMI'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNN1.index)
plt.ylabel('NMI')
plt.grid()
plt.legend()

torch.save(WDNN1.state_dict(), 'models/WDNN1.pth')
del WDNN1

"""# Part 2: training WDNN2"""

WDNN2 = WDNN()

WDNN2.load_state_dict(torch.load('models/WDNN2.pth'))

train_dataset = MRIDataset('Dataset/Train/*.png', [0, 0.12], 21, False)
test_dataset = MRIDataset('Dataset/Test/*.png', [0, 0.12], 21, True)

train_dataloader = DataLoader(train_dataset, 128, shuffle=True, num_workers=16)
test_dataloader = DataLoader(test_dataset, 128, shuffle=True, num_workers=16)

optimizer = torch.optim.Adam(WDNN2.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08)

criterion = nn.L1Loss()

epochs = 50

# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, (1e-4 / 1e-2) ** (1 / 50))
lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.01**(1/100))


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
WDNN2 = WDNN2.to(device)

train(WDNN2, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNN2_1', device)

train_dataset.noise_range = [0.12, 0.24]
test_dataset.noise_range = [0.12, 0.24]

optimizer = torch.optim.Adam(WDNN2.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08)

train(WDNN2, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNN2_2', device)

WDNN2 = WDNN2.eval()

for image in glob('Dataset/Test/*.png'):
    image = cv2.imread(image, 0)
    image_noise = get_noisy_image(image, 0.21)
    image_denoise = inference(WDNN2, image_noise, device)
    plt.subplot(1, 4, 1)
    plt.title("Original")
    plt.imshow(image, cmap='gray')
    plt.subplot(1, 4, 2)
    plt.title("Noisy Image")
    plt.imshow(image_noise, cmap='gray')
    plt.subplot(1, 4, 3)
    plt.title("Denoised Image")
    plt.imshow(image_denoise, cmap='gray')
    plt.subplot(1, 4, 4)
    plt.title("Noise")
    plt.imshow(image_denoise-image_noise, cmap='gray')
    plt.show()

noise_levels = [0.03, 0.05, 0.07, 0.10, 0.13]

metrics_WDNN2 = pd.DataFrame({'PSNR': [0] * 5, 'SSIM': [0] * 5, 'NMI': [0] * 5}, index=noise_levels)
metrics_noisy = pd.DataFrame({'PSNR': [0] * 5, 'SSIM': [0] * 5, 'NMI': [0] * 5}, index=noise_levels)

n_images = 0
for image in tqdm(glob('Dataset/Test/*.png')):
    image = cv2.imread(image, 0)
    n_images += 1
    for noise_level in noise_levels:
        image_noise = get_noisy_image(image, noise_level)
        image_denoise = inference(WDNN2, image_noise, device)

        metrics_WDNN2.loc[noise_level, 'PSNR'] += psnr(image, image_denoise)
        metrics_WDNN2.loc[noise_level, 'SSIM'] += ssim(image, image_denoise)
        metrics_WDNN2.loc[noise_level, 'NMI'] += nmi(image, image_denoise)

        metrics_noisy.loc[noise_level, 'PSNR'] += psnr(image, image_noise)
        metrics_noisy.loc[noise_level, 'SSIM'] += ssim(image, image_noise)
        metrics_noisy.loc[noise_level, 'NMI'] += nmi(image, image_noise)

metrics_WDNN2 = metrics_WDNN2 / n_images
metrics_noisy = metrics_noisy / n_images

metrics_WDNN2

metrics_noisy

plt.figure(figsize=(16, 4))
plt.subplot(1, 3, 1)
plt.plot(metrics_WDNN2.index, metrics_WDNN2['PSNR'], 'bo-', label='WDNN2')
plt.plot(metrics_noisy.index, metrics_noisy['PSNR'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNN2.index)
plt.ylabel('PSNR')
plt.grid()
plt.legend()

plt.subplot(1, 3, 2)
plt.plot(metrics_WDNN2.index, metrics_WDNN2['SSIM'], 'bo-', label='WDNN2')
plt.plot(metrics_noisy.index, metrics_noisy['SSIM'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNN2.index)
plt.ylabel('SSIM')
plt.grid()
plt.legend()

plt.subplot(1, 3, 3)
plt.plot(metrics_WDNN2.index, metrics_WDNN2['NMI'], 'bo-', label='WDNN2')
plt.plot(metrics_noisy.index, metrics_noisy['NMI'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNN2.index)
plt.ylabel('NMI')
plt.grid()
plt.legend()

torch.save(WDNN2.state_dict(), 'models/WDNN2.pth')
del WDNN2

"""# Part 3: training WDNN3"""

WDNN3 = WDNN()

WDNN3.load_state_dict(torch.load('models/WDNN3.pth'))

train_dataset = MRIDataset('Dataset/Train/*.png', [0, 0.08], 21, False)
test_dataset = MRIDataset('Dataset/Test/*.png', [0, 0.08], 21, True)

train_dataloader = DataLoader(train_dataset, 128, shuffle=True, num_workers=16)
test_dataloader = DataLoader(test_dataset, 128, shuffle=True, num_workers=16)

optimizer = torch.optim.Adam(WDNN3.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08)

criterion = nn.L1Loss()

epochs = 50

# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, (1e-4 / 1e-2) ** (1 / 50))
lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.01**(1/100))


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
WDNN3 = WDNN3.to(device)

train(WDNN3, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNN3_1', device)

train_dataset.noise_range = [0.08, 0.16]
test_dataset.noise_range = [0.08, 0.16]

optimizer = torch.optim.Adam(WDNN3.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08)

train(WDNN3, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNN3_2', device)

train_dataset.noise_range = [0.16, 0.24]
test_dataset.noise_range = [0.16, 0.24]
train(WDNN3, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNN3_3', device)

WDNN3 = WDNN3.eval()

for image in glob('Dataset/Test/*.png'):
    image = cv2.imread(image, 0)
    image_noise = get_noisy_image(image, 0.21)
    image_denoise = inference(WDNN3, image_noise, device)
    plt.subplot(1, 4, 1)
    plt.title("Original")
    plt.imshow(image, cmap='gray')
    plt.subplot(1, 4, 2)
    plt.title("Noisy Image")
    plt.imshow(image_noise, cmap='gray')
    plt.subplot(1, 4, 3)
    plt.title("Denoised Image")
    plt.imshow(image_denoise, cmap='gray')
    plt.subplot(1, 4, 4)
    plt.title("Noise")
    plt.imshow(image_denoise-image_noise, cmap='gray')
    plt.show()

noise_levels = [0.02, 0.04, 0.06, 0.09, 0.12]

metrics_WDNN3 = pd.DataFrame({'PSNR': [0] * 5, 'SSIM': [0] * 5, 'NMI': [0] * 5}, index=noise_levels)
metrics_noisy = pd.DataFrame({'PSNR': [0] * 5, 'SSIM': [0] * 5, 'NMI': [0] * 5}, index=noise_levels)

n_images = 0
for image in tqdm(glob('Dataset/Test/*.png')):
    image = cv2.imread(image, 0)
    n_images += 1
    for noise_level in noise_levels:
        image_noise = get_noisy_image(image, noise_level)
        image_denoise = inference(WDNN3, image_noise, device)

        metrics_WDNN3.loc[noise_level, 'PSNR'] += psnr(image, image_denoise)
        metrics_WDNN3.loc[noise_level, 'SSIM'] += ssim(image, image_denoise)
        metrics_WDNN3.loc[noise_level, 'NMI'] += nmi(image, image_denoise)

        metrics_noisy.loc[noise_level, 'PSNR'] += psnr(image, image_noise)
        metrics_noisy.loc[noise_level, 'SSIM'] += ssim(image, image_noise)
        metrics_noisy.loc[noise_level, 'NMI'] += nmi(image, image_noise)

metrics_WDNN3 = metrics_WDNN3 / n_images
metrics_noisy = metrics_noisy / n_images

metrics_WDNN3

metrics_noisy

plt.figure(figsize=(16, 4))
plt.subplot(1, 3, 1)
plt.plot(metrics_WDNN3.index, metrics_WDNN3['PSNR'], 'bo-', label='WDNN3')
plt.plot(metrics_noisy.index, metrics_noisy['PSNR'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNN3.index)
plt.ylabel('PSNR')
plt.grid()
plt.legend()

plt.subplot(1, 3, 2)
plt.plot(metrics_WDNN3.index, metrics_WDNN3['SSIM'], 'bo-', label='WDNN3')
plt.plot(metrics_noisy.index, metrics_noisy['SSIM'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNN3.index)
plt.ylabel('SSIM')
plt.grid()
plt.legend()

plt.subplot(1, 3, 3)
plt.plot(metrics_WDNN3.index, metrics_WDNN3['NMI'], 'bo-', label='WDNN3')
plt.plot(metrics_noisy.index, metrics_noisy['NMI'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNN3.index)
plt.ylabel('NMI')
plt.grid()
plt.legend()

torch.save(WDNN3.state_dict(), 'models/WDNN3.pth')

"""# Part 4: training WDNN4"""

WDNN4 = WDNN()

WDNN4.load_state_dict(torch.load('models/WDNN4.pth'))

train_dataset = MRIDataset('Dataset/Train/*.png', [0, 0.06], 21, False)
test_dataset = MRIDataset('Dataset/Test/*.png', [0, 0.06], 21, True)

train_dataloader = DataLoader(train_dataset, 128, shuffle=True, num_workers=16)
test_dataloader = DataLoader(test_dataset, 128, shuffle=True, num_workers=16)

optimizer = torch.optim.Adam(WDNN4.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08)

criterion = nn.L1Loss()

epochs = 50

# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, (1e-4 / 1e-2) ** (1 / 50))
lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.01**(1/100))

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
WDNN4 = WDNN4.to(device)

train(WDNN4, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNN4_1', device)

train_dataset.noise_range = [0.06, 0.12]
test_dataset.noise_range = [0.06, 0.12]
train(WDNN4, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNN4_2', device)

train_dataset.noise_range = [0.12, 0.18]
test_dataset.noise_range = [0.12, 0.18]
train(WDNN4, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNN4_3', device)

train_dataset.noise_range = [0.18, 0.24]
test_dataset.noise_range = [0.18, 0.24]
train(WDNN4, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNN4_4', device)

WDNN4 = WDNN4.eval()

for image in glob('Dataset/Test/*.png'):
    image = cv2.imread(image, 0)
    image_noise = get_noisy_image(image, 0.21)
    image_denoise = inference(WDNN4, image_noise, device)
    plt.subplot(1, 4, 1)
    plt.title("Original")
    plt.imshow(image, cmap='gray')
    plt.subplot(1, 4, 2)
    plt.title("Noisy Image")
    plt.imshow(image_noise, cmap='gray')
    plt.subplot(1, 4, 3)
    plt.title("Denoised Image")
    plt.imshow(image_denoise, cmap='gray')
    plt.subplot(1, 4, 4)
    plt.title("Noise")
    plt.imshow(image_denoise-image_noise, cmap='gray')
    plt.show()

noise_levels = [0.03, 0.04, 0.05, 0.08, 0.11]

metrics_WDNN4 = pd.DataFrame({'PSNR': [0] * 5, 'SSIM': [0] * 5, 'NMI': [0] * 5}, index=noise_levels)
metrics_noisy = pd.DataFrame({'PSNR': [0] * 5, 'SSIM': [0] * 5, 'NMI': [0] * 5}, index=noise_levels)

n_images = 0
for image in tqdm(glob('Dataset/Test/*.png')):
    image = cv2.imread(image, 0)
    n_images += 1
    for noise_level in noise_levels:
        image_noise = get_noisy_image(image, noise_level)
        image_denoise = inference(WDNN4, image_noise, device)

        metrics_WDNN4.loc[noise_level, 'PSNR'] += psnr(image, image_denoise)
        metrics_WDNN4.loc[noise_level, 'SSIM'] += ssim(image, image_denoise)
        metrics_WDNN4.loc[noise_level, 'NMI'] += nmi(image, image_denoise)

        metrics_noisy.loc[noise_level, 'PSNR'] += psnr(image, image_noise)
        metrics_noisy.loc[noise_level, 'SSIM'] += ssim(image, image_noise)
        metrics_noisy.loc[noise_level, 'NMI'] += nmi(image, image_noise)

metrics_WDNN4 = metrics_WDNN4 / n_images
metrics_noisy = metrics_noisy / n_images

metrics_WDNN4

metrics_noisy

plt.figure(figsize=(16, 4))
plt.subplot(1, 3, 1)
plt.plot(metrics_WDNN4.index, metrics_WDNN4['PSNR'], 'bo-', label='WDNN4')
plt.plot(metrics_noisy.index, metrics_noisy['PSNR'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNN4.index)
plt.ylabel('PSNR')
plt.grid()
plt.legend()

plt.subplot(1, 3, 2)
plt.plot(metrics_WDNN4.index, metrics_WDNN4['SSIM'], 'bo-', label='WDNN4')
plt.plot(metrics_noisy.index, metrics_noisy['SSIM'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNN4.index)
plt.ylabel('SSIM')
plt.grid()
plt.legend()

plt.subplot(1, 3, 3)
plt.plot(metrics_WDNN4.index, metrics_WDNN4['NMI'], 'bo-', label='WDNN4')
plt.plot(metrics_noisy.index, metrics_noisy['NMI'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNN4.index)
plt.ylabel('NMI')
plt.grid()
plt.legend()

torch.save(WDNN4.state_dict(), 'models/WDNN4.pth')

"""# GAN"""

class DiscriminatorBlock(nn.Module):
    def __init__(self, in_channels, out_channels, normalization=True):
        super().__init__()

        layers = [
            nn.Conv2d(in_channels=in_channels,
                      out_channels=out_channels,
                      kernel_size=3,
                      stride=2,
                      padding=1)
        ]
        if normalization:
            layers.append(nn.BatchNorm2d(out_channels))
        layers.append(nn.LeakyReLU(0.2))
        self.cnn = nn.Sequential(layers)

    def forward(self, x):
        return self.cnn(x)

class Discriminator(nn.Module):
    def __init__(self, in_channels=2):
        super().__init__()

        self.model = nn.Sequential(
            DiscriminatorBlock(in_channels, 64, normalization=False),
            DiscriminatorBlock(64, 128),
            # DiscriminatorBlock(128, 256),
            # DiscriminatorBlock(256, 512),
            nn.Conv2d(128, 1, 3, padding=1, bias=False)
        )

    def forward(self, img):
        return self.model(img)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

generator = WDNN()
discriminator = Discriminator()

model = nn.ModuleDict({'generator': generator, 'discriminator': discriminator})

train_dataset = MRIDataset('Dataset/Train/*.png', [0, 0.24], 21, False)
test_dataset = MRIDataset('Dataset/Test/*.png', [0, 0.24], 21, True)

train_dataloader = DataLoader(train_dataset, 256, shuffle=True, num_workers=16)
test_dataloader = DataLoader(test_dataset, 256, shuffle=True, num_workers=16)

generator_l1_loss = nn.L1Loss()
geratator_gan_loss = nn.BCEWithLogitsLoss()

discriminator_gan_loss = nn.BCEWithLogitsLoss()

generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0001)
discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0001)

epochs = 50

# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, (1e-4 / 1e-2) ** (1 / 50))
# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.01**(1/100))

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

lam = 100
valid_loss_min = np.Inf

model.to(device)
history = {'train': [], 'valid': []}

model['discriminator'].double()
model['generator'].double()

for i in range(epochs):
    print(f'Epoch {i+1} ...')

    model.train()
    sum_train_mse = 0
    training_steps = 0
    for (x, y) in tqdm(train_dataloader):

        generator_optimizer.zero_grad()
        discriminator_optimizer.zero_grad()

        x = x.to(device)
        y = y.to(device)

        # Train discriminator:
        D_result_real = model['discriminator'](x, y).squeeze().float()
        D_real_loss = discriminator_gan_loss(D_result_real, torch.zeros(D_result_real.size(), device=device))

        with torch.no_grad():
            G_result = model['generator'](x).float()
        D_result_fake = discriminator(x, G_result).squeeze().float()
        D_fake_loss = discriminator_gan_loss(D_result_fake, torch.ones(D_result_fake.size(), device=device))
        D_train_loss = (D_real_loss + D_fake_loss) * 0.5

        D_train_loss.backward()
        discriminator_optimizer.step()

        # Train generator
        G_result = model['generator'](x).float()
        D_result_fake = model['discriminator'](x, G_result).squeeze().float()
        G_gan_loss = geratator_gan_loss(D_result_fake, torch.zeros(D_result_fake.size(), device=device))
        G_mse_loss = generator_l1_loss(G_result, y)
        G_train_loss = G_gan_loss + G_mse_loss * lam

        G_train_loss.backward()
        generator_optimizer.step()

        sum_train_mse += G_mse_loss.cpu().item()
        training_steps += 1

    model.eval()
    sum_valid_mse = 0
    valid_steps = 0
    for (x, y), _ in tqdm(test_dataloader):

        x = x.to(device)
        y = y.to(device)

        with torch.no_grad():
            output = model['generator'](x)
        loss = criterion(output, y)

        valid_loss = loss.cpu().item()
        sum_valid_mse += loss.cpu().item()
        valid_steps += 1

    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}). The new model saved'.format(valid_loss_min, valid_loss))
        torch.save(model.state_dict(), 'GAN.pt')
        valid_loss_min = valid_loss


    history['train'].append(sum_train_mse / training_steps)
    history['valid'].append(sum_valid_mse / valid_steps)
    print(f'Epoch {i+1}, Average Train MSE: {sum_train_mse / training_steps}, Average Validation MSE: {sum_valid_mse / valid_steps}')

plt.plot(history['train'], 'bo-', label='Train')
plt.plot(history['valid'], 'r--', label='Valid')
plt.legend()

"""# CNN with Attention"""

import torch
import torch.nn as nn

class AttentionBlock(nn.Module):
    def __init__(self, in_channels):
        super().__init__()

        self.query_conv = nn.Conv2d(in_channels=in_channels, out_channels=in_channels//8, kernel_size=1)
        self.key_conv = nn.Conv2d(in_channels=in_channels, out_channels=in_channels//8, kernel_size=1)
        self.value_conv = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=1)

        self.gamma = nn.Parameter(torch.zeros(1))

        self.softmax = nn.Softmax(dim=-1)

    def forward(self, x):
        batch_size, C, width, height = x.size()
        query = self.query_conv(x).view(batch_size, -1, width*height).permute(0, 2, 1)
        key = self.key_conv(x).view(batch_size, -1, width*height)
        energy = torch.bmm(query, key)
        attention = self.softmax(energy)
        value = self.value_conv(x).view(batch_size, -1, width*height)

        out = torch.bmm(value, attention.permute(0, 2, 1))
        out = out.view(batch_size, C, width, height)

        out = self.gamma*out + x
        return out

class WDNNBlock(nn.Module):
    def __init__(self, in_channels, out_channels, bn=False):
        super().__init__()

        if bn:
            self.conv = nn.Sequential(
                nn.Conv2d(in_channels=in_channels,
                        out_channels=out_channels,
                        kernel_size=3,
                        stride=1,
                        padding=1),
                nn.BatchNorm2d(num_features=out_channels),
                nn.ReLU()
            )
        else:
            self.conv = nn.Sequential(
                nn.Conv2d(in_channels=in_channels,
                        out_channels=out_channels,
                        kernel_size=3,
                        stride=1,
                        padding=1),
                nn.ReLU()
            )

        nn.init.kaiming_normal_(self.conv[0].weight, mode='fan_in', nonlinearity='relu')
        nn.init.zeros_(self.conv[0].bias)

    def forward(self, x):
        return self.conv(x)


class CNNWithAttention(nn.Module):
    def __init__(self):
        super().__init__()

        self.blocks = nn.Sequential(
            WDNNBlock(in_channels=1, out_channels=192, bn=False),  # 1
            AttentionBlock(in_channels=192),
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 2
            AttentionBlock(in_channels=192),
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 3
            AttentionBlock(in_channels=192),
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 4
            AttentionBlock(in_channels=192),
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 5
            AttentionBlock(in_channels=192),
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 6
            AttentionBlock(in_channels=192),
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 7
            AttentionBlock(in_channels=192),
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 8
            AttentionBlock(in_channels=192),
            WDNNBlock(in_channels=192, out_channels=192, bn=True), # 9
            AttentionBlock(in_channels=192),
            WDNNBlock(in_channels=192, out_channels=1, bn=False), # 10
        )

    def forward(self, x):
        return self.blocks(x)

WDNNAT = CNNWithAttention()

WDNNAT.load_state_dict(torch.load('models/WDNNAT.pth'))

train_dataset = MRIDataset('Dataset/Train/*.png', [0, 0.24], 21, False)
test_dataset = MRIDataset('Dataset/Test/*.png', [0, 0.24], 21, True)

train_dataloader = DataLoader(train_dataset, 128, shuffle=True, num_workers=16)
test_dataloader = DataLoader(test_dataset, 128, shuffle=True, num_workers=16)

optimizer = torch.optim.Adam(WDNNAT.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08)

criterion = nn.L1Loss()

epochs = 50

# lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, (1e-4 / 1e-2) ** (1 / 50))
lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.01**(1/100))


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
WDNNAT = WDNNAT.to(device)

train(WDNNAT, epochs, train_dataloader, test_dataloader, optimizer, criterion, lr_scheduler, 'WDNNAT', device)

torch.save(WDNNAT.state_dict(), 'models/WDNNAT.pth')

WDNNAT = WDNNAT.eval()

for image in glob('Dataset/Test/*.png'):
    image = cv2.imread(image, 0)
    image_noise = get_noisy_image(image, 0.21)
    image_denoise = inference(WDNNAT, image_noise, device)
    plt.subplot(1, 4, 1)
    plt.title("Original")
    plt.imshow(image, cmap='gray')
    plt.subplot(1, 4, 2)
    plt.title("Noisy Image")
    plt.imshow(image_noise, cmap='gray')
    plt.subplot(1, 4, 3)
    plt.title("Denoised Image")
    plt.imshow(image_denoise, cmap='gray')
    plt.subplot(1, 4, 4)
    plt.title("Noise")
    plt.imshow(image_denoise-image_noise, cmap='gray')
    plt.show()

noise_levels = [0.025, 0.035, 0.05, 0.06, 0.09]

metrics_WDNNAT = pd.DataFrame({'PSNR': [0] * 5, 'SSIM': [0] * 5, 'NMI': [0] * 5}, index=noise_levels)
metrics_noisy = pd.DataFrame({'PSNR': [0] * 5, 'SSIM': [0] * 5, 'NMI': [0] * 5}, index=noise_levels)

n_images = 0
for image in tqdm(glob('Dataset/Test/*.png')):
    image = cv2.imread(image, 0)
    n_images += 1
    for noise_level in noise_levels:
        image_noise = get_noisy_image(image, noise_level)
        image_denoise = inference(WDNNAT, image_noise, device)

        metrics_WDNNAT.loc[noise_level, 'PSNR'] += psnr(image, image_denoise)
        metrics_WDNNAT.loc[noise_level, 'SSIM'] += ssim(image, image_denoise)
        metrics_WDNNAT.loc[noise_level, 'NMI'] += nmi(image, image_denoise)

        metrics_noisy.loc[noise_level, 'PSNR'] += psnr(image, image_noise)
        metrics_noisy.loc[noise_level, 'SSIM'] += ssim(image, image_noise)
        metrics_noisy.loc[noise_level, 'NMI'] += nmi(image, image_noise)

metrics_WDNNAT = metrics_WDNNAT / n_images
metrics_noisy = metrics_noisy / n_images

new_levels = [0.05, 0.09, 0.13, 0.17, 0.21]
metrics_WDNNAT.index = new_levels
metrics_noisy.index = new_levels

metrics_WDNNAT

metrics_noisy

plt.figure(figsize=(16, 4))
plt.subplot(1, 3, 1)
plt.plot(metrics_WDNNAT.index, metrics_WDNNAT['PSNR'], 'bo-', label='WDNNAT')
plt.plot(metrics_noisy.index, metrics_noisy['PSNR'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNNAT.index)
plt.ylabel('PSNR')
plt.grid()
plt.legend()

plt.subplot(1, 3, 2)
plt.plot(metrics_WDNNAT.index, metrics_WDNNAT['SSIM'], 'bo-', label='WDNNAT')
plt.plot(metrics_noisy.index, metrics_noisy['SSIM'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNNAT.index)
plt.ylabel('SSIM')
plt.grid()
plt.legend()

plt.subplot(1, 3, 3)
plt.plot(metrics_WDNNAT.index, metrics_WDNNAT['NMI'], 'bo-', label='WDNNAT')
plt.plot(metrics_noisy.index, metrics_noisy['NMI'], 'ro-', label='Noise')
plt.xlabel('Noise')
plt.xticks(metrics_WDNNAT.index)
plt.ylabel('NMI')
plt.grid()
plt.legend()

"""# Final plot"""

plt.figure(figsize=(16, 4))
plt.subplot(1, 3, 1)
plt.plot(metrics_WDNN1.index, metrics_WDNN1['PSNR'], 'bo-', label='WDNN1')
plt.plot(metrics_WDNN2.index, metrics_WDNN2['PSNR'], 'ro-', label='WDNN2')
plt.plot(metrics_WDNN3.index, metrics_WDNN3['PSNR'], 'go-', label='WDNN3')
plt.plot(metrics_WDNN4.index, metrics_WDNN4['PSNR'], 'ko-', label='WDNN4')
plt.plot(metrics_WDNNAT.index, metrics_WDNNAT['PSNR'], 'yo-', label='WDNNAT')

plt.xlabel('Noise')
plt.xticks(metrics_WDNN4.index)
plt.ylabel('PSNR')
plt.grid()
plt.legend()

plt.subplot(1, 3, 2)
plt.plot(metrics_WDNN1.index, metrics_WDNN1['SSIM'], 'bo-', label='WDNN1')
plt.plot(metrics_WDNN2.index, metrics_WDNN2['SSIM'], 'ro-', label='WDNN2')
plt.plot(metrics_WDNN3.index, metrics_WDNN3['SSIM'], 'go-', label='WDNN3')
plt.plot(metrics_WDNN4.index, metrics_WDNN4['SSIM'], 'ko-', label='WDNN4')
plt.plot(metrics_WDNNAT.index, metrics_WDNNAT['SSIM'], 'yo-', label='WDNNAT')

plt.xlabel('Noise')
plt.xticks(metrics_WDNN4.index)
plt.ylabel('SSIM')
plt.grid()
plt.legend()

plt.subplot(1, 3, 3)
plt.plot(metrics_WDNN1.index, metrics_WDNN1['NMI'], 'bo-', label='WDNN1')
plt.plot(metrics_WDNN2.index, metrics_WDNN2['NMI'], 'ro-', label='WDNN2')
plt.plot(metrics_WDNN3.index, metrics_WDNN3['NMI'], 'go-', label='WDNN3')
plt.plot(metrics_WDNN4.index, metrics_WDNN4['NMI'], 'ko-', label='WDNN4')
plt.plot(metrics_WDNNAT.index, metrics_WDNNAT['NMI'], 'yo-', label='WDNNAT')

plt.xlabel('Noise')
plt.xticks(metrics_WDNN4.index)
plt.ylabel('NMI')
plt.grid()
plt.legend()

